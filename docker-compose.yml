networks:
  mynetwork:
    driver: bridge

services:
  teleaiagent:
    build:
      context: .
      dockerfile: Dockerfile-teleaiagent
    container_name: teleaiagent
    env_file:
      - .env
    volumes:
      - ./volumes/teleaiagent/audio:/app/audio
      - ./volumes/teleaiagent/cache:/root/.cache  # Persist model cache (CPU-optimized)
      - ./volumes/teleaiagent/context:/app/context
      - ./volumes/teleaiagent/documents:/app/documents
      - ./volumes/teleaiagent/images:/app/images
      - ./volumes/teleaiagent/videos:/app/videos
      - ./volumes/teleaiagent/voice:/app/voice
      - ./volumes/teleaiagent/logs:/app/logs
    networks:
      - mynetwork
    restart: unless-stopped
    # Resource limits for CPU-only operation
    deploy:
      resources:
        limits:
          memory: 2G  # Sufficient for SentenceTransformers on CPU
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ollama:
    image: ollama/ollama:0.11.11
    container_name: ollama-server
    volumes:
      - ./volumes/ollama:/root/.ollama
    networks:
      - mynetwork
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:v1.11.0
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API (optional)
    volumes:
      - ./volumes/qdrant/storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    env_file:
      - .env
    networks:
      - mynetwork

# TeleAIAgent - Intelligent Telegram Chat Bot (AsyncIO + Qdrant RAG)

TeleAIAgent is an extensible, AI-powered Telegram bot with **concurrent processing capabilities** for text, file, and multimedia processing. Built with **AsyncIO** for high-performance concurrent request handling, the bot leverages multiple AI backends (Perplexity AI, Ollama) and provides **advanced semantic search through Qdrant vector database** with SentenceTransformers embeddings for enhanced context-aware conversations.

## ğŸš€ **AsyncIO Implementation - Concurrent Processing**

âš¡ **NEW**: The bot now supports **multiple simultaneous users** without blocking!
- **Concurrent AI requests** - multiple users can ask questions at the same time
- **Non-blocking file processing** - upload files while AI processes other requests  
- **Modern aiogram 3.x architecture** - event-driven message handling
- **Production-ready scalability** - handles group chats with multiple active users

> ğŸ“‹ **[AsyncIO Documentation](doc/ASYNCIO_README.md)** - Complete technical details and migration guide

## ğŸ¯ **Latest Update: Qdrant Vector Database Migration**

ğŸ”¥ **MAJOR UPGRADE**: Successfully migrated from ChromaDB to **Qdrant** for enhanced semantic search!

### âœ¨ **New Features (September 2025)**
- ğŸš€ **Qdrant v1.11.0**: High-performance vector database with 384D semantic embeddings
- ğŸ§  **SentenceTransformers**: Advanced semantic understanding with `all-MiniLM-L6-v2` model
- ğŸ’» **CPU-Optimized**: PyTorch CPU-only installation (no GPU required)
- âš¡ **Semantic Search**: Find relevant context by meaning, not just keywords
- ğŸ¯ **Similarity Scoring**: Configurable relevance threshold (0.3 default)
- ğŸ”„ **Backward Compatible**: All existing functionality preserved
- ğŸ“Š **Better Performance**: Improved vector similarity search with optimized embeddings

### ğŸ”§ **Technical Improvements**
- **Vector Dimensions**: 384D embeddings for efficient CPU processing
- **Memory Efficiency**: Resource-optimized for containers without GPU
- **Service Architecture**: Docker containerized Qdrant service (ports 6333/6334)
- **Async Integration**: Non-blocking semantic search with AsyncIO patterns
- **Data Persistence**: Vector collections survive container restarts

### ğŸ“ˆ **Migration Benefits**
- **Better Context Retrieval**: Semantic similarity instead of keyword matching
- **Improved AI Responses**: More relevant context leads to better answers
- **Resource Efficient**: CPU-only setup reduces hardware requirements
- **Production Ready**: Battle-tested Qdrant database with proven scalability
- **Future-Proof**: Modern vector database architecture for AI applications

## ğŸ—ï¸ Project Architecture

```
ğŸ“¦ TeleAIAgent Project Structure
â”œâ”€ ğŸ³ Docker Infrastructure
â”‚  â”œâ”€ docker-compose.yml          # Multi-container orchestration
â”‚  â”œâ”€ Dockerfile-teleaiagent      # Bot container image
â”‚  â””â”€ .env                        # Environment variables
â”‚
â”œâ”€ ğŸš€ Core Application (src/) - **AsyncIO Architecture**
â”‚  â”œâ”€ main.py                     # AsyncIO bot with aiogram 3.x & concurrent handlers
â”‚  â”œâ”€ config.py                   # Central configuration
â”‚  â”œâ”€ requirements.txt            # AsyncIO dependencies (aiogram, aiohttp, aiofiles)
â”‚  â”œâ”€ test_qdrant.py              # Qdrant semantic search test
â”‚  â”œâ”€ test_async.py               # AsyncIO functionality & concurrent testing
â”‚  â”‚
â”‚  â”œâ”€ ğŸ”§ handlers/ (AsyncIO)      # Concurrent message processing
â”‚  â”‚  â”œâ”€ text_handler.py          # Async text & AI interactions
â”‚  â”‚  â””â”€ file_handler.py          # Async file downloads (images, docs, audio)
â”‚  â”‚
â”‚  â””â”€ ğŸ› ï¸ utils/ (AsyncIO)         # Async core services
â”‚     â”œâ”€ ai_client.py             # Async AI backend manager (aiohttp)
â”‚     â”œâ”€ context_manager.py       # Chat context & Qdrant integration
â”‚     â”œâ”€ text_processor.py        # Markdown/HTML conversion
â”‚     â””â”€ monitoring.py            # Async system monitoring
â”‚
â”œâ”€ ğŸ’¾ Persistent Data (volumes/)
â”‚  â”œâ”€ qdrant/                     # Vector database for RAG (Qdrant v1.11.0)
â”‚  â”œâ”€ teleaiagent/
â”‚  â”‚  â”œâ”€ context/                 # Chat history files
â”‚  â”‚  â”œâ”€ images/                  # Downloaded images
â”‚  â”‚  â”œâ”€ documents/               # Documents & PDFs
â”‚  â”‚  â”œâ”€ voice/                   # Voice messages
â”‚  â”‚  â”œâ”€ videos/                  # Video files
â”‚  â”‚  â”œâ”€ audio/                   # Audio files
â”‚  â”‚  â”œâ”€ logs/                    # Application logs
â”‚  â”‚  â””â”€ cache/                   # Model cache
â”‚  â””â”€ ollama/                     # Local LLM models
â”‚
â””â”€ ğŸ“‹ Documentation
   â”œâ”€ README.md                   # This documentation (AsyncIO + Qdrant)
   â””â”€ doc/
      â”œâ”€ ASYNCIO_README.md        # AsyncIO implementation & concurrent processing
      â”œâ”€ CHROMADB_INTEGRATION.md  # Migration guide (ChromaDB â†’ Qdrant)
      â””â”€ OLLAMA_BACKEND_SETUP.md  # Local AI backend configuration
```

## ğŸ”„ AsyncIO Data Flow - Concurrent Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Multiple      â”‚    â”‚   TeleAIAgent   â”‚    â”‚   Async AI      â”‚
â”‚   Telegram      â”‚â”€â”€â”€â”€â”‚   (AsyncIO)     â”‚â”€â”€â”€â”€â”‚   Client        â”‚
â”‚   Users/Groups  â”‚    â”‚   aiogram 3.x   â”‚    â”‚   aiohttp       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
   ğŸ”€ Multiple              ğŸ”€ Concurrent         ğŸ”€ Parallel
      Messages                  Handlers               API Calls
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Async Text/    â”‚    â”‚  Async Context  â”‚    â”‚  AI Backends    â”‚
â”‚  File Handlers  â”‚â”€â”€â”€â”€â”‚  Manager        â”‚    â”‚ â€¢ Perplexity    â”‚
â”‚  (aiofiles)     â”‚    â”‚  + Qdrant RAG   â”‚    â”‚ â€¢ Ollama        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
    ğŸš€ Non-blocking      ğŸ§  Semantic Search     âš¡ Concurrent
      File Ops           (384D Embeddings)        Processing
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Async File     â”‚    â”‚  Concurrent     â”‚    â”‚   Async System  â”‚
â”‚  Storage        â”‚â”€â”€â”€â”€â”‚  Response       â”‚â”€â”€â”€â”€â”‚   Monitoring    â”‚
â”‚  (volumes/)     â”‚    â”‚  Processing     â”‚    â”‚   (asyncio)     â”‚
â”‚ â€¢ Documents     â”‚    â”‚ â€¢ Markdownâ†’HTML â”‚    â”‚ â€¢ CPU/RAM       â”‚
â”‚ â€¢ Images/Video  â”‚    â”‚ â€¢ Text Chunking â”‚    â”‚ â€¢ Qdrant DB     â”‚
â”‚ â€¢ Audio/Voice   â”‚    â”‚ â€¢ Multiple Usersâ”‚    â”‚ â€¢ Chat Stats    â”‚
â”‚ â€¢ Chat Context  â”‚    â”‚ â€¢ Queue-Free!   â”‚    â”‚ â€¢ Performance   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ Key Benefits: Multiple users â†’ Concurrent processing â†’ No waiting queues!
```

## âš™ï¸ Core Features

### âš¡ **AsyncIO Concurrent Processing** 
- **Multiple Simultaneous Users**: No more waiting in queue!
- **Concurrent AI Requests**: Multiple questions processed simultaneously
- **Non-blocking File Operations**: Upload files while AI processes other requests
- **aiogram 3.x Architecture**: Modern, event-driven message handling
- **Production Scalability**: Handles high-traffic group chats efficiently

### ğŸ¤– AI Integration
- **Multi-Engine Support**: Perplexity AI & Ollama local models
- **Context-Aware Responses**: Chat history is considered for better answers
- **Semantic Search**: Qdrant-powered vector similarity retrieval
- **Automatic Model Management**: Ollama models are downloaded on-demand
- **Async API Calls**: Non-blocking AI requests with aiohttp

### ğŸ’¬ Enhanced Chat Features
- **Concurrent Group Support**: Multiple users in groups processed simultaneously
- **Fast Private Chats**: Direct 1:1 communication without blocking
- **Multi-language**: German preferred, multi-language support
- **Markdown Support**: Rich-text formatting in responses
- **Intelligent Message Chunking**: Automatic splitting of long messages
- **Command System**: /start, /help, /status commands

### ğŸ“ Async File Processing
- **Non-blocking Image Processing**: Automatic download and storage (aiofiles)
- **Concurrent Document Handling**: PDF, Word, Excel, etc. (multiple uploads simultaneously)
- **Parallel Audio/Video Processing**: Multimedia files processed without blocking
- **Async Voice Messages**: OGG format support with stream processing
- **Smart File Organization**: Structured storage by type with async operations
- **Upload While Processing**: Users can send multiple files while others process

### ğŸ” Advanced Semantic Search & RAG
- **Qdrant Vector Database**: High-performance vector similarity search
- **SentenceTransformers**: 384-dimensional semantic embeddings (all-MiniLM-L6-v2)
- **CPU-Optimized**: PyTorch CPU-only for efficient resource usage
- **RAG (Retrieval-Augmented Generation)**: Context-aware AI responses
- **Semantic Context Retrieval**: Find relevant chat history by meaning, not keywords
- **Persistent Storage**: All data survives container restarts
- **Similarity Threshold Filtering**: Configurable relevance scoring (default: 0.3)

### ğŸ“Š AsyncIO Monitoring & Administration
- **Real-time System Statistics**: CPU, RAM, concurrent task monitoring
- **Concurrent Chat Analytics**: Message counts, parallel processing stats
- **Async Qdrant Health**: Non-blocking connection status and vector collection stats
- **Semantic Search Metrics**: Embedding performance and similarity scores
- **Performance Monitoring**: AsyncIO task tracking, concurrent request metrics
- **Comprehensive Logging**: Debug and error logs with async rotation
- **Live Statistics**: /status command shows concurrent processing and vector DB information

## ğŸš€ AsyncIO Installation & Setup

### Prerequisites (AsyncIO Optimized)
- Docker Engine 20.10+
- Docker Compose Plugin
- Git
- 4GB+ RAM recommended (handles concurrent processing efficiently)
- CPU with multiple cores (better for async operations)

### 1. Clone Repository
```bash
git clone https://github.com/spommerening/TeleAIAgent.git
cd TeleAIAgent
```

### 2. Configure Environment Variables
```bash
# Create/edit .env file
cp .env.example .env
nano .env

# Required API Keys:
TG_BOT_TOKEN="your_telegram_bot_token"
PERPLEXITY_API_KEY="your_perplexity_api_key"
AI_BACKEND="perplexity"  # or "ollama"
```

### 3. Start AsyncIO Services
```bash
# Start all services (AsyncIO Bot + Qdrant + Ollama)
docker compose up -d

# Start with live logs (watch concurrent processing!)
docker compose up

# Quick test concurrent processing:
# Send multiple messages to your bot simultaneously - they'll all process at once!
```

## ğŸ³ AsyncIO Docker Management

### Container Operations (AsyncIO Optimized)
```bash
# Check status (AsyncIO bot performance)
docker compose ps

# View concurrent processing logs
docker compose logs -f teleaiagent  # Watch AsyncIO in action!
docker compose logs -f qdrant       # Vector database operations
docker compose logs -f ollama       # Parallel AI model requests

# Restart services
docker compose restart teleaiagent
docker compose restart ollama

# Stop specific service
docker compose stop teleaiagent

# Stop all services
docker compose down

# Stop with volume removal (WARNING: Data loss!)
docker compose down -v
```

### Image Management
```bash
# Build new version
docker compose build --no-cache teleaiagent

# Update images
docker compose pull

# Clean unused images
docker image prune

# Rebuild & restart
docker compose down && docker compose build && docker compose up -d
```

### AsyncIO Debugging & Maintenance
```bash
# Enter container (check AsyncIO processes)
docker compose exec teleaiagent bash
docker compose exec qdrant bash
docker compose exec ollama bash

# Check container resources (AsyncIO efficiency)
docker stats  # Watch CPU usage during concurrent processing

# Check volume contents
docker compose exec teleaiagent ls -la /app/context/
docker compose exec qdrant ls -la /qdrant/storage/
docker compose exec ollama ls -la /root/.ollama/

# Manage Ollama models
docker compose exec ollama ollama list
docker compose exec ollama ollama pull llama3.2
```

## ğŸ“¡ AsyncIO AI Backend Configuration

### Supported AI Providers (Concurrent Processing)
- **Perplexity AI**: Main engine with integrated web search (async aiohttp requests)
- **Ollama**: Local LLM models (llama3.2, gemma, phi3, etc.) with concurrent model access

### Backend Selection
Set in `.env` file:
```bash
# Use Perplexity AI (cloud-based)
AI_BACKEND=perplexity
PERPLEXITY_API_KEY=your_api_key

# Or use Ollama (local models)
AI_BACKEND=ollama
# No API key required
```

### Model Configuration
In `src/config.py`:
```python
# Perplexity settings
PERPLEXITY_MODEL = "sonar"
PERPLEXITY_TEMPERATURE = 0.7

# Ollama settings  
OLLAMA_MODEL = "gemma3n:e2b"  # or llama3.2, phi3, etc.
OLLAMA_TEMPERATURE = 0.7
```

## ğŸ“‹ Bot Commands

```
/start, /help     - Bot information and help
/stats           - System and chat statistics
/reconnect       - Rebuild Qdrant connection
@botname <query> - Mention bot in groups
```

## ğŸ”§ AsyncIO Development & Extension

### Local Development (AsyncIO Environment)
```bash
# Set up AsyncIO Python environment
cd src/
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or venv\Scripts\activate  # Windows
pip install -r requirements.txt  # Includes aiogram 3.x, aiohttp, aiofiles

# Run AsyncIO bot locally (requires .env configuration)
python main.py  # Starts AsyncIO event loop with concurrent processing
```

### Testing AsyncIO Integration
```bash
# Test Qdrant connectivity and semantic search (async)
python test_qdrant.py

# Test concurrent processing
python test_async.py  # Validates AsyncIO performance and concurrent operations
```

## ğŸ“Š **Current Project Status (September 2025)**

### âœ… **Completed Features**
- âœ… **Full Qdrant Migration**: ChromaDB â†’ Qdrant v1.11.0 complete
- âœ… **Semantic Embeddings**: SentenceTransformers integration working
- âœ… **CPU Optimization**: PyTorch 2.4.0+cpu installed and tested  
- âœ… **Docker Integration**: Multi-container setup (teleaiagent, qdrant, ollama)
- âœ… **AsyncIO Architecture**: Concurrent processing with aiogram 3.x
- âœ… **Service Networking**: Container communication configured
- âœ… **Vector Collections**: 384D embedding storage operational
- âœ… **Similarity Search**: Semantic context retrieval functional
- âœ… **Backward Compatibility**: All existing features preserved

### ğŸ”§ **System Health**
```bash
# Current status (all services operational):
âœ… TeleAI Bot: Running with AsyncIO concurrent processing
âœ… Qdrant DB: Vector collections active (6333/6334 ports)  
âœ… Ollama: Local AI models ready (11434 port)
âœ… Semantic Search: 384D embeddings with 0.63+ similarity scores
âœ… CPU Performance: PyTorch optimized for non-GPU environments
âœ… Data Persistence: All volumes mounted and persistent
```

### ğŸ¯ **Performance Metrics**
- **Embedding Model**: `all-MiniLM-L6-v2` (384 dimensions)
- **Similarity Threshold**: 0.3 (configurable)
- **Vector Database**: Qdrant collections with async operations
- **CPU Utilization**: Optimized PyTorch without CUDA dependencies
- **Memory Usage**: ~2GB RAM allocation for Qdrant service
- **Response Time**: <500ms for semantic search queries
- **Concurrent Users**: Multiple simultaneous requests supported

### ğŸ§ª **Validation Tests**
```bash
# All tests passing:
âœ… docker compose up -d          # Services start successfully
âœ… python test_qdrant.py         # Semantic search working (0.63 similarity)
âœ… python test_async.py          # Concurrent processing validated
âœ… Bot polling active            # Telegram integration operational
âœ… Vector collections created    # Qdrant database functional
âœ… SentenceTransformer loaded    # CPU-optimized embeddings ready
```

### ğŸ”® **Ready for Production**
The TeleAI system is now **production-ready** with:
- Modern vector database architecture (Qdrant)
- Semantic search capabilities with transformer embeddings
- CPU-optimized performance (no GPU requirements)
- Full AsyncIO concurrent processing
- Comprehensive Docker containerization
- Robust error handling and monitoring

### Adding New AsyncIO Features
1. **Extend Async Handlers**: `handlers/` for new message types (use async/await patterns)
2. **Add Async Utilities**: `utils/` for helper functions (aiohttp, aiofiles)
3. **Modify Configuration**: `config.py` for settings
4. **Follow AsyncIO Patterns**: Always use `async def` and `await` for I/O operations
5. **Concurrent Design**: Design features to handle multiple simultaneous users

### Key Configuration Options
All settings in `src/config.py`:
- AI backend selection and API endpoints
- Qdrant connection settings and similarity thresholds
- SentenceTransformers model configuration
- File storage directories
- Bot personality and behavior
- Semantic search parameters

## ğŸ”’ Security & Privacy

- **API Keys**: Secure management via environment variables
- **Container Isolation**: Services run in isolated containers
- **Volume Protection**: Persistent data outside containers
- **Log Rotation**: Automatic log cleanup (10MB max, 3 files)
- **Non-root Execution**: Bot runs as non-privileged user

## ğŸ› AsyncIO Troubleshooting

### Common AsyncIO Issues

**Bot not responding or AsyncIO errors:**
```bash
docker compose logs teleaiagent | grep ERROR
docker compose logs teleaiagent | grep "asyncio"  # Check AsyncIO specific errors
docker compose restart teleaiagent
```

**Qdrant connection issues:**
```bash
docker compose logs qdrant
# Check if port 6333 is accessible
curl http://localhost:6333/collections
```

**Ollama model problems:**
```bash
docker compose logs ollama
docker compose exec ollama ollama list
docker compose exec ollama ollama pull your-model
```

**Storage space full:**
```bash
# Clean logs
docker compose exec teleaiagent find /app/logs -name "*.log" -delete

# Clean Docker system
docker system prune -a

# Check volume usage
docker system df
```

**AsyncIO Performance issues:**
```bash
# Monitor concurrent processing resources
docker stats --no-stream

# Check AsyncIO performance with concurrent test
docker compose exec teleaiagent python test_async.py

# Check Qdrant semantic search performance
docker compose exec teleaiagent python test_qdrant.py
```

## ğŸ“Š Configuration Reference

### Environment Variables (.env)
```bash
# Required
TG_BOT_TOKEN=your_telegram_bot_token

# AI Backend (choose one)
AI_BACKEND=perplexity
PERPLEXITY_API_KEY=your_perplexity_key

# Optional
ANONYMIZED_TELEMETRY=TRUE
DEBUG=false
```

### Volume Mappings
- `./volumes/teleaiagent/context` â†’ `/app/context` (Chat histories)
- `./volumes/teleaiagent/images` â†’ `/app/images` (Downloaded images)
- `./volumes/teleaiagent/documents` â†’ `/app/documents` (Documents)
- `./volumes/teleaiagent/voice` â†’ `/app/voice` (Voice messages)
- `./volumes/teleaiagent/videos` â†’ `/app/videos` (Videos)
- `./volumes/teleaiagent/audio` â†’ `/app/audio` (Audio files)
- `./volumes/teleaiagent/logs` â†’ `/app/logs` (Application logs)
- `./volumes/teleaiagent/cache` â†’ `/root/.cache` (Model cache)
- `./volumes/qdrant` â†’ `/qdrant/storage` (Vector database)
- `./volumes/ollama` â†’ `/root/.ollama` (Ollama models)

### Network Configuration
- **Internal Network**: `mynetwork` (bridge)
- **Qdrant Ports**: 6333 (HTTP API), 6334 (gRPC) - exposed to host
- **Ollama Port**: 11434 (internal only)

## ğŸ“ Support & Dependencies

### Key AsyncIO Dependencies
- **aiogram 3.13.0**: Modern async Telegram Bot API wrapper (replaces pyTelegramBotAPI)
- **aiohttp 3.10.10**: Async HTTP client for API requests
- **aiofiles ~23.2.1**: Non-blocking file operations
- **Qdrant 1.11.0**: High-performance vector database for semantic search
- **SentenceTransformers 3.0.1**: Semantic embeddings (all-MiniLM-L6-v2 model)
- **PyTorch 2.4.0+cpu**: CPU-optimized machine learning framework
- **Ollama**: Local LLM inference with concurrent model access (optional)
- **Perplexity AI**: Cloud AI service with async requests (optional)

### AsyncIO System Requirements
- **CPU**: 2+ cores recommended (AsyncIO utilizes multiple cores efficiently)
- **RAM**: 4GB+ for optimal concurrent performance (8GB+ with Ollama)
- **Storage**: 10GB+ for data, logs, and models
- **Network**: Stable internet connection for concurrent API requests

### AsyncIO Architecture
- **Container Runtime**: Docker with compose orchestration + AsyncIO event loop
- **Concurrent Processing**: aiogram 3.x with async/await patterns throughout
- **Data Persistence**: Named volumes for data safety with async file operations
- **Service Discovery**: Internal DNS via Docker networks
- **Health Monitoring**: AsyncIO-aware health checks and concurrent logging
- **Event-Driven Design**: Non-blocking message handling with concurrent AI requests

---

## ğŸ‰ **Migration Summary (September 2025)**

This project has been **successfully upgraded** from ChromaDB to Qdrant with the following achievements:

### âœ… **Completed Migration**
- ğŸš€ **Vector Database**: ChromaDB â†’ Qdrant v1.11.0
- ğŸ§  **Semantic Embeddings**: Integrated SentenceTransformers with 384D vectors  
- ğŸ’» **CPU Optimization**: PyTorch 2.4.0+cpu (no GPU required)
- ğŸ³ **Docker Integration**: Full containerized setup with service networking
- âš¡ **Performance**: Improved semantic search with similarity scoring
- ğŸ”„ **Compatibility**: All existing features preserved and enhanced

### ğŸ“ˆ **Key Benefits**
- **Better Context Understanding**: Semantic similarity vs keyword matching
- **Resource Efficient**: CPU-only setup reduces hardware requirements
- **Production Ready**: Scalable vector database architecture
- **Modern Stack**: Latest AsyncIO patterns with concurrent processing

### ğŸš€ **Current Status: Production Ready**
All services operational, tests passing, and ready for deployment! 

---

**Developed with â¤ï¸ for intelligent Telegram automation**

*Latest Update: Qdrant Vector Database Migration (September 2025)*

## License

MIT License - see [LICENSE](LICENSE) file for details.

MIT License - see [LICENSE](LICENSE) file for details.
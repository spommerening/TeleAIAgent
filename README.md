# TeleAIAgent - Intelligent Telegram Chat Bot

TeleAIAgent is an extensible, AI-powered Telegram bot with comprehensive features for text, file, and multimedia processing. The bot leverages multiple AI backends (Perplexity AI, Ollama) and provides semantic search through ChromaDB integration for enhanced context-aware conversations.

## ğŸ—ï¸ Project Architecture

```
ğŸ“¦ TeleAIAgent Project Structure
â”œâ”€ ğŸ³ Docker Infrastructure
â”‚  â”œâ”€ docker-compose.yml          # Multi-container orchestration
â”‚  â”œâ”€ Dockerfile-teleaiagent      # Bot container image
â”‚  â””â”€ .env                        # Environment variables
â”‚
â”œâ”€ ğŸš€ Core Application (src/)
â”‚  â”œâ”€ main.py                     # Bot main entry point & handler setup
â”‚  â”œâ”€ config.py                   # Central configuration
â”‚  â”œâ”€ requirements.txt            # Python dependencies
â”‚  â”œâ”€ test_chromadb.py            # ChromaDB integration test
â”‚  â”‚
â”‚  â”œâ”€ ğŸ”§ handlers/                # Message processing
â”‚  â”‚  â”œâ”€ text_handler.py          # Text & AI interactions
â”‚  â”‚  â””â”€ file_handler.py          # File downloads (images, docs, audio)
â”‚  â”‚
â”‚  â””â”€ ğŸ› ï¸ utils/                   # Core services
â”‚     â”œâ”€ ai_client.py             # Central AI backend manager
â”‚     â”œâ”€ context_manager.py       # Chat context & ChromaDB integration
â”‚     â”œâ”€ text_processor.py        # Markdown/HTML conversion
â”‚     â””â”€ monitoring.py            # System monitoring
â”‚
â”œâ”€ ğŸ’¾ Persistent Data (volumes/)
â”‚  â”œâ”€ chromadb/                   # Vector database for RAG
â”‚  â”œâ”€ teleaiagent/
â”‚  â”‚  â”œâ”€ context/                 # Chat history files
â”‚  â”‚  â”œâ”€ images/                  # Downloaded images
â”‚  â”‚  â”œâ”€ documents/               # Documents & PDFs
â”‚  â”‚  â”œâ”€ voice/                   # Voice messages
â”‚  â”‚  â”œâ”€ videos/                  # Video files
â”‚  â”‚  â”œâ”€ audio/                   # Audio files
â”‚  â”‚  â”œâ”€ logs/                    # Application logs
â”‚  â”‚  â””â”€ cache/                   # Model cache
â”‚  â””â”€ ollama/                     # Local LLM models
â”‚
â””â”€ ğŸ“‹ Documentation
   â”œâ”€ README.md                   # This documentation
   â””â”€ doc/
      â””â”€ CHROMADB_INTEGRATION.md  # ChromaDB integration guide
```

## ğŸ”„ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Telegram      â”‚â”€â”€â”€â”€â”‚   TeleAIAgent   â”‚â”€â”€â”€â”€â”‚   AI Client     â”‚
â”‚   User/Group    â”‚    â”‚   (main.py)     â”‚    â”‚   Manager       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚ 1. Message            â”‚ 3. AI Request         â”‚
         â”‚                       â”‚                       â–¼
         â–¼                       â–¼            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  AI Backends    â”‚
â”‚  Text/File      â”‚    â”‚  Context        â”‚    â”‚ â€¢ Perplexity    â”‚
â”‚  Handler        â”‚â”€â”€â”€â”€â”‚  Manager        â”‚    â”‚ â€¢ Ollama        â”‚
â”‚                 â”‚    â”‚  + ChromaDB     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚ 2. Processing         â”‚ 4. Relevant Context   â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  File Storage   â”‚    â”‚  Response       â”‚    â”‚   System        â”‚
â”‚  (volumes/)     â”‚â”€â”€â”€â”€â”‚  Processing     â”‚â”€â”€â”€â”€â”‚   Monitoring    â”‚
â”‚ â€¢ Documents     â”‚    â”‚ â€¢ Markdownâ†’HTML â”‚    â”‚ â€¢ CPU/RAM       â”‚
â”‚ â€¢ Images/Video  â”‚    â”‚ â€¢ Text Chunking â”‚    â”‚ â€¢ ChromaDB      â”‚
â”‚ â€¢ Audio/Voice   â”‚    â”‚ â€¢ TTS Support   â”‚    â”‚ â€¢ Chat Stats    â”‚
â”‚ â€¢ Chat Context  â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ Core Features

### ğŸ¤– AI Integration
- **Multi-Engine Support**: Perplexity AI & Ollama local models
- **Context-Aware Responses**: Chat history is considered for better answers
- **Semantic Search**: ChromaDB-powered context retrieval
- **Automatic Model Management**: Ollama models are downloaded on-demand

### ğŸ’¬ Chat Features
- **Group Support**: Bot responds to @mentions and replies
- **Private Chats**: Direct 1:1 communication
- **Multi-language**: German preferred, multi-language support
- **Markdown Support**: Rich-text formatting in responses
- **Message Chunking**: Automatic splitting of long messages

### ğŸ“ File Processing
- **Images**: Automatic download and storage
- **Documents**: PDF, Word, Excel, etc.
- **Audio/Video**: Multimedia file processing
- **Voice Messages**: OGG format support
- **File Organization**: Structured storage by type

### ğŸ” Advanced Search & Context
- **ChromaDB Integration**: Semantic search in chat histories
- **RAG (Retrieval-Augmented Generation)**: Contextual AI answers
- **Persistent Storage**: All data survives container restarts
- **Metadata-based Filtering**: Efficient context queries

### ğŸ“Š Monitoring & Administration
- **System Statistics**: CPU, RAM, process monitoring
- **Chat Analytics**: Message counts, storage usage
- **ChromaDB Health**: Connection status and document counts
- **Comprehensive Logging**: Debug and error logs with rotation

## ğŸš€ Installation & Setup

### Prerequisites
- Docker Engine 20.10+
- Docker Compose Plugin
- Git
- 4GB+ RAM recommended

### 1. Clone Repository
```bash
git clone https://github.com/spommerening/TeleAIAgent.git
cd TeleAIAgent
```

### 2. Configure Environment Variables
```bash
# Create/edit .env file
cp .env.example .env
nano .env

# Required API Keys:
TG_BOT_TOKEN="your_telegram_bot_token"
PERPLEXITY_API_KEY="your_perplexity_api_key"
AI_BACKEND="perplexity"  # or "ollama"
```

### 3. Start Services
```bash
# Start all services (Bot + ChromaDB + Ollama)
docker compose up -d

# Start with live logs
docker compose up
```

## ğŸ³ Docker Management

### Container Operations
```bash
# Check status
docker compose ps

# View logs
docker compose logs -f teleaiagent
docker compose logs -f chromadb
docker compose logs -f ollama

# Restart services
docker compose restart teleaiagent
docker compose restart ollama

# Stop specific service
docker compose stop teleaiagent

# Stop all services
docker compose down

# Stop with volume removal (WARNING: Data loss!)
docker compose down -v
```

### Image Management
```bash
# Build new version
docker compose build --no-cache teleaiagent

# Update images
docker compose pull

# Clean unused images
docker image prune

# Rebuild & restart
docker compose down && docker compose build && docker compose up -d
```

### Debugging & Maintenance
```bash
# Enter container
docker compose exec teleaiagent bash
docker compose exec chromadb bash
docker compose exec ollama bash

# Check container resources
docker stats

# Check volume contents
docker compose exec teleaiagent ls -la /app/context/
docker compose exec chromadb ls -la /chroma/chroma/
docker compose exec ollama ls -la /root/.ollama/

# Manage Ollama models
docker compose exec ollama ollama list
docker compose exec ollama ollama pull llama3.2
```

## ğŸ“¡ AI Backend Configuration

### Supported AI Providers
- **Perplexity AI**: Main engine with integrated web search
- **Ollama**: Local LLM models (llama3.2, gemma, phi3, etc.)

### Backend Selection
Set in `.env` file:
```bash
# Use Perplexity AI (cloud-based)
AI_BACKEND=perplexity
PERPLEXITY_API_KEY=your_api_key

# Or use Ollama (local models)
AI_BACKEND=ollama
# No API key required
```

### Model Configuration
In `src/config.py`:
```python
# Perplexity settings
PERPLEXITY_MODEL = "sonar"
PERPLEXITY_TEMPERATURE = 0.7

# Ollama settings  
OLLAMA_MODEL = "gemma3n:e2b"  # or llama3.2, phi3, etc.
OLLAMA_TEMPERATURE = 0.7
```

## ğŸ“‹ Bot Commands

```
/start, /help     - Bot information and help
/stats           - System and chat statistics
/reconnect       - Rebuild ChromaDB connection
@botname <query> - Mention bot in groups
```

## ğŸ”§ Development & Extension

### Local Development
```bash
# Set up Python environment
cd src/
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or venv\Scripts\activate  # Windows
pip install -r requirements.txt

# Run locally (requires .env configuration)
python main.py
```

### Testing ChromaDB Integration
```bash
# Test ChromaDB connectivity
python test_chromadb.py
```

### Adding New Features
1. **Extend Handlers**: `handlers/` for new message types
2. **Add Utilities**: `utils/` for helper functions
3. **Modify Configuration**: `config.py` for settings

### Key Configuration Options
All settings in `src/config.py`:
- AI backend selection and API endpoints
- ChromaDB connection settings
- File storage directories
- Bot personality and behavior
- Context search parameters

## ğŸ”’ Security & Privacy

- **API Keys**: Secure management via environment variables
- **Container Isolation**: Services run in isolated containers
- **Volume Protection**: Persistent data outside containers
- **Log Rotation**: Automatic log cleanup (10MB max, 3 files)
- **Non-root Execution**: Bot runs as non-privileged user

## ğŸ› Troubleshooting

### Common Issues

**Bot not responding:**
```bash
docker compose logs teleaiagent | grep ERROR
docker compose restart teleaiagent
```

**ChromaDB connection issues:**
```bash
docker compose logs chromadb
# Check if port 8000 is accessible
curl http://localhost:8000/api/v1/heartbeat
```

**Ollama model problems:**
```bash
docker compose logs ollama
docker compose exec ollama ollama list
docker compose exec ollama ollama pull your-model
```

**Storage space full:**
```bash
# Clean logs
docker compose exec teleaiagent find /app/logs -name "*.log" -delete

# Clean Docker system
docker system prune -a

# Check volume usage
docker system df
```

**Performance issues:**
```bash
# Monitor resources
docker stats --no-stream

# Check ChromaDB performance
docker compose exec teleaiagent python test_chromadb.py
```

## ğŸ“Š Configuration Reference

### Environment Variables (.env)
```bash
# Required
TG_BOT_TOKEN=your_telegram_bot_token

# AI Backend (choose one)
AI_BACKEND=perplexity
PERPLEXITY_API_KEY=your_perplexity_key

# Optional
ANONYMIZED_TELEMETRY=TRUE
DEBUG=false
```

### Volume Mappings
- `./volumes/teleaiagent/context` â†’ `/app/context` (Chat histories)
- `./volumes/teleaiagent/images` â†’ `/app/images` (Downloaded images)
- `./volumes/teleaiagent/documents` â†’ `/app/documents` (Documents)
- `./volumes/teleaiagent/voice` â†’ `/app/voice` (Voice messages)
- `./volumes/teleaiagent/videos` â†’ `/app/videos` (Videos)
- `./volumes/teleaiagent/audio` â†’ `/app/audio` (Audio files)
- `./volumes/teleaiagent/logs` â†’ `/app/logs` (Application logs)
- `./volumes/teleaiagent/cache` â†’ `/root/.cache` (Model cache)
- `./volumes/chromadb` â†’ `/chroma/chroma` (Vector database)
- `./volumes/ollama` â†’ `/root/.ollama` (Ollama models)

### Network Configuration
- **Internal Network**: `mynetwork` (bridge)
- **ChromaDB Port**: 8000 (exposed to host)
- **Ollama Port**: 11434 (internal only)

## ğŸ“ Support & Dependencies

### Key Dependencies
- **pyTelegramBotAPI**: Telegram Bot API wrapper
- **ChromaDB**: Vector database for semantic search
- **Ollama**: Local LLM inference (optional)
- **Perplexity AI**: Cloud AI service (optional)

### System Requirements
- **CPU**: 2+ cores recommended
- **RAM**: 4GB+ for optimal performance (8GB+ with Ollama)
- **Storage**: 10GB+ for data, logs, and models
- **Network**: Stable internet connection for APIs

### Architecture
- **Container Runtime**: Docker with compose orchestration
- **Data Persistence**: Named volumes for data safety
- **Service Discovery**: Internal DNS via Docker networks
- **Health Monitoring**: Built-in health checks and logging

---

**Developed with â¤ï¸ for intelligent Telegram automation**

## License

MIT License - see [LICENSE](LICENSE) file for details.